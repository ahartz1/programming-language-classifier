{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from lib.import_lang_data import *\n",
    "from lib.lang_featurizers import *\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gcc           58\n",
       "scala         43\n",
       "csharp        41\n",
       "yarv          39\n",
       "clojure       38\n",
       "python3       36\n",
       "ocaml         35\n",
       "perl          34\n",
       "jruby         34\n",
       "sbcl          34\n",
       "racket        29\n",
       "php           29\n",
       "hack          26\n",
       "javascript    25\n",
       "tcl            9\n",
       "c              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in assignment's test files\n",
    "X_assignment_test, y_assignment_test = read_tests()\n",
    "\n",
    "# read corpus into lang_data, lang_results\n",
    "languages = ['gcc', 'c', 'csharp', 'sbcl', 'clojure', 'ghc' 'java', 'javascript',\n",
    "             'ocaml', 'perl', 'php', 'hack', 'py', 'python3', 'jruby', 'yarv', 'rb',\n",
    "             'scala', 'racket', 'tcl']\n",
    "lang_data, lang_results = read_polyglot(languages)\n",
    "lang_info = pd.DataFrame(lang_results)\n",
    "lang_info[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ruby           73\n",
       "C              59\n",
       "PHP            55\n",
       "Scala          43\n",
       "C#             41\n",
       "Clojure        38\n",
       "Python         36\n",
       "OCaml          35\n",
       "Perl           34\n",
       "Common Lisp    34\n",
       "Scheme         29\n",
       "JavaScript     25\n",
       "TCL             9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_info = match_extensions(lang_info)\n",
    "lang_results = list(lang_info[0])\n",
    "lang_info[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score: 0.984375\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          C       1.00      1.00      1.00        12\n",
      "         C#       1.00      1.00      1.00        11\n",
      "    Clojure       1.00      1.00      1.00         7\n",
      "Common Lisp       1.00      1.00      1.00         6\n",
      " JavaScript       1.00      0.83      0.91         6\n",
      "      OCaml       1.00      1.00      1.00        11\n",
      "        PHP       0.94      1.00      0.97        16\n",
      "       Perl       1.00      0.89      0.94         9\n",
      "     Python       1.00      1.00      1.00        12\n",
      "       Ruby       0.93      1.00      0.97        14\n",
      "      Scala       1.00      1.00      1.00        14\n",
      "     Scheme       1.00      1.00      1.00         6\n",
      "        TCL       1.00      1.00      1.00         4\n",
      "\n",
      "avg / total       0.99      0.98      0.98       128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lang_featurizer = make_union(\n",
    "    BagOfWordsFeaturizer(52),\n",
    "    FunctionFeaturizer(presence_nil,\n",
    "                       presence_nil_caps,\n",
    "                       presence_null,\n",
    "                       presence_none,\n",
    "#                        presence_start_double_semicolons,\n",
    "#                        presence_start_hashes,\n",
    "#                        presence_bar_hash,\n",
    "                       presence_paren_define,\n",
    "                       percent_start_and_end_parenthesis,\n",
    "                       longest_run_of_parenthesis,\n",
    "                       longest_run_of_curly_braces,\n",
    "                       single_closing_braces_per_line,\n",
    "                       presence_function_js,\n",
    "                       presence_while,\n",
    "                       presence_do,\n",
    "                       presence_var,\n",
    "                       presence_for_js,\n",
    "                       presence_plus_equals,\n",
    "                       presence_js_case_open_square,\n",
    "#                        final_semicolons_per_line,\n",
    "                       presence_void,\n",
    "                       presence_public,\n",
    "                       presence_bool,\n",
    "                       presence_struct,\n",
    "                       presence_new,\n",
    "                       presence_this_dot,\n",
    "#                        presence_int,\n",
    "                       presence_module_line,\n",
    "                       presence_extend_line,\n",
    "                       presence_require_line,\n",
    "#                        presence_end,\n",
    "                       presence_multiple_end,\n",
    "                       presence_def_no_colon,\n",
    "                       presence_at,\n",
    "                       presence_double_at,\n",
    "#                        presence_puts,\n",
    "#                        presence_puts_not_proc,\n",
    "                       presence_elif,\n",
    "                       presence_dot_times,\n",
    "                       presence_paren_defn,\n",
    "                       presence_paren_ns,\n",
    "                       percent_consecutive_closing_paren,\n",
    "                       presence_taskloop,\n",
    "                       presence_runtask,\n",
    "                       presence_from_import_line,\n",
    "                       presence_import_line,\n",
    "                       presence_print_paren,\n",
    "                       presence_dot_join,\n",
    "                       presence_dot_format,\n",
    "                       presence_dot_values,\n",
    "                       presence_dunder_name,\n",
    "                       presence_dunder_init,\n",
    "                       presence_def_colon,\n",
    "                       presence_let,\n",
    "#                        presence_snake_case,\n",
    "                       presence_naked_colon,\n",
    "                       presence_naked_lt_minus,\n",
    "                       percent_dollar_lower,\n",
    "                       presence_dollar_minus_gt,\n",
    "                       presence_function_php,\n",
    "                       presence_gt_question,\n",
    "                       presence_elseif,\n",
    "                       presence_proc,\n",
    "                       percent_curly_braces,\n",
    "                       )\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(lang_data, lang_results)\n",
    "\n",
    "pipe = make_pipeline(lang_featurizer, DecisionTreeClassifier())\n",
    "pipe.fit(X_train, y_train)\n",
    "print('R^2 score: {}\\n'.format(pipe.score(X_test, y_test)))\n",
    "print(classification_report(y_test, pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now to test with the assignment's tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score: 0.59375\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          C       0.00      0.00      0.00         0\n",
      "    Clojure       1.00      0.25      0.40         4\n",
      "Common Lisp       0.00      0.00      0.00         0\n",
      "    Haskell       0.00      0.00      0.00         3\n",
      "       Java       0.00      0.00      0.00         2\n",
      " JavaScript       1.00      1.00      1.00         4\n",
      "      OCaml       0.50      1.00      0.67         2\n",
      "        PHP       0.00      0.00      0.00         3\n",
      "       Perl       0.00      0.00      0.00         0\n",
      "     Python       1.00      0.75      0.86         4\n",
      "       Ruby       0.38      1.00      0.55         3\n",
      "      Scala       1.00      0.50      0.67         2\n",
      "     Scheme       1.00      1.00      1.00         3\n",
      "        TCL       0.67      1.00      0.80         2\n",
      "\n",
      "avg / total       0.64      0.59      0.56        32\n",
      "\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 4 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 2]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahartz1/TIY/programming-language-classifier/.direnv/python-3.4.3/lib/python3.4/site-packages/sklearn/metrics/classification.py:958: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/ahartz1/TIY/programming-language-classifier/.direnv/python-3.4.3/lib/python3.4/site-packages/sklearn/metrics/classification.py:960: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('R^2 score: {}\\n'.format(pipe.score(X_assignment_test, y_assignment_test)))\n",
    "print(classification_report(y_assignment_test, pipe.predict(X_assignment_test)))\n",
    "print(confusion_matrix(y_assignment_test, pipe.predict(X_assignment_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "It is not easy to accurately identify the programming language used to create a snippet. It takes checking for several specific syntax structures for each language. I did not have time to write enough of these to sufficiently identify the assignment's test snippets, but I was able to get my training set to very accurately identify its test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
